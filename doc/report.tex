\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsthm, minted, hyperref, enumerate, graphics, graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{Loom Proof of Concept}
\author{Mahesh Khanwalkar}
\date{}

\begin{document}
    \maketitle
    \section{Introduction}

    Project Loom is an effort to add scoped, one-shot delimited continuations to Java, along with the
    necessary runtime support within the JVM. Third-party implementations of delimited continuations, like
    Kilim required an explicit, after-compilation weaving process; however, this is not necessary within
    Loom.

    \subsection{Loom API}

    The way of creating continuations is through the aptly-named Continuation class, which encapsulates a
    Runnable target. The continuation can be started for the first time using a call to the run method:

    \begin{lstlisting}
    // Runnable body is wrapped within the continuation
    Continuation cont = new Continuation(body); 
    cont.run();
    \end{lstlisting}

    This call performs all the necessary setup required, which includes the support for handling yielding.
    Within the Runnable body, the continuation can be yielded using a static call to Continuation.yield,
    which will cause the call to run to return. However, the same condition is true when the continuation
    simplify finishes. Therefore, it is up to the caller to check whether the continuation actually finished.
    It is up to the user of the continuation to resume it, which can be done using the same run call.

    \begin{lstlisting}
    if(cont.isDone()) {
        // The continuation has finished
    } else {
        // The continuation has yielded (suspended)
        // Calling run will resume right after the point of suspension.
        cont.run();
    }
    \end{lstlisting}

    \subsection{Limitations}
    The API is still currently under active development, so there are still some limitations. The only
    exposed state of a continuation is whether it is done or not. There is no way to tell from another thread
    that the continuation has yielded.

    The documentation mentions a Fiber class, which would manage the scheduling of continuations and states
    that continuations are not necessarily meant to be used directly, since they are quite low-level.
    However, there seems to be a gap between the documentation and the current state of the code base. 

    There was a Fiber class in an earlier build, but it was marked package private, so it is quite likely
    that it was not supposed to be used directly. In addition, in newer builds, it looks like the class has
    been removed completely. The only public, relatively-stable interface is the Continuation class. 

    Since Project Loom is under active development, it is natural that there are still many bugs. JVM crashes
    do occur occasionally, so some of the runtime support does seem to have some issues that need to be
    resolved. Debugging also occasionally causes the JVM to crash as well which is not ideal. However, for
    the most part, the current state of Loom is stable enough and feature-ready enough to be used to
    implement higher level parallelism constructs.

    \section{Purpose}

    The main objective of this proof-of-concept is to demonstrate how to implement certain high level
    parallelism constructs with the features provided in Loom. This implementation was done from the ground
    up to allow for design flexibility and faster completion than trying to migrate parts of the existing
    Habanero Java library. While the end goal is to do this migration, this project acts as a logic stepping
    stone, hopefully guiding the effort through the initial stages.

    The two high level parallelism constructs that were chosen were \textbf{async} and \textbf{finish}, which
    are arguably the most fundamental. Many other constructs, like parallel for, can be built on top of these
    so it makes sense to start here. Both the runtime design and the library interface were designed to be
    similar to the original HJ library implementation. Functional interfaces and lambdas, just like with the
    original HJLib, were employed to mimic the construct style used by X10 and the Habanero Java language.

    This objective was achieved -- both \textbf{async} and \textbf{finish} were fully implemented and tested
    with simple examples. The details of the runtime implementation, continuation setup, and other important
    information is layed out within the next couple sections. There are still some small issues with the
    current source; however, those are runtime related: the constructs are working as expected. 

    Lastly, the code itself has been documented extensively. Since the end goal of this proof-of-concept is
    to serve as a starting point for a larger migration effort, adequate documentation would be very helpful.
    Both the runtime and construct aspects have lengthy javadocs that explain everything in detail. Debugging
    the components is also relatively straightforward, although the issues with continuation debugging do
    occasionally make things complicated. However, this will ideally be resolved as Project Loom matures with
    time.

    \section{Design Process}

    The project was split into two logically-separate units: constructs and runtime support. The constructs
    define the \textbf{async} and \textbf{finish} methods while the runtime support implements all the task
    management and scheduling internals.

    \subsection{Constructs}

    The constructs were defined within a Construct class which contains static methods. In addition to the
    \textbf{async} and \textbf{finish} methods, there is also a \textbf{launchApp} method. This is used to
    enter a scope where the runtime is active and ready to accept tasks. Once control returns from this
    method, the runtime automatically waits on any remaining tasks and then shuts down, freeing up any
    resources that were allocated.

    Since the runtime is only active within the \textbf{launchApp} scope, it follows that the high-level
    parallelism constructs must be called within this scope. The following code snippet demonstrates how this
    would look like:

    \begin{lstlisting}
        launchApp(() -> myJob());
        ...
        public void myJob()
        {
            finish(() -> {
                System.out.println("Task #1");
                async(() -> {
                    System.out.println("Task #2");
                });
            });
        }
    \end{lstlisting}

    The myJob method encapsulates a single job which is made up of two tasks. The task creation and
    management is all handled by the runtime, since this method is passed to the launchApp method. It is also
    possible to directly provide the body of myJob to launchApp, as shown below:

    \begin{lstlisting}
        launchApp(() -> {
            finish(() -> {
                System.out.println("Task #1");
                async(() -> {
                    System.out.println("Task #2");
                });
            });
        });
    \end{lstlisting}

    For very small code snippets, this makes sense. However, for the most part, it is best to encapsulate the
    job into its own method. There are no restrictions when it comes to the method composition of the job:
    control can freely enter and return from as many methods as so desired (constrained by stack limits)

    \subsection{Runtime}

    The runtime is where all of the actual task management work happens. The constructs merely act as a
    convenient wrapper which calls into the runtime for all of its needs. 

    \subsubsection{Construct Implementation}

    \begin{lstlisting}
    /**
     * Launch a new "application" to run on the runtime framework
     * @param body - root body of the task
     * @throws InterruptedException - if the wait-to-finish is interrupted
     */
    public static void launchApp(Runnable body) throws InterruptedException
    {
        // Only one runtime can be launched at a time
        if(runtime != null)
            return;

        runtime = new LoomRuntime();
        runtime.submitRoot(body);
        runtime.waitOnRoot();
        runtime.shutdown();
    }
    \end{lstlisting}

    As described earlier, the launchApp method will initialise the runtime and submit the provided body as
    the root task. Therefore, all jobs start out with a single task, but have the option of creating new ones
    via the \textbf{async} construct. Once the root task has been submitted, the method waits until the
    runtime indicates that this task and all its children have completed.

    It is important to note that the root task has an implicit finish scope. That is, the root task cannot
    be considered complete until all of its child tasks have also completed. Therefore, regardless of whether
    there is a call to finish with the runnable body, then runtime ensures that this implicit finish behaviour
    is preserved.

    Another important note is that the Construct API only directly deals with Runnable. The continuations are
    only seen within the runtime itself. This is due to the fact that there is no weaving process -- support
    for continuations is at a JVM level. Therefore, there is no need for special interfaces or annotations
    to indicate which methods need to be weaved after compilation. 

    The implementations for \textbf{async} and \textbf{finish} are even simpler, since they directly call the
    runtime without any additional work:

    \begin{lstlisting}
    /**
     * Spawn an async task to execute the body
     *
     * This call should only be executed within the launchApp { ... }
     * scope, since the Loom Runtime needs to be initialised.
     *
     * The 'body' specified will be wrapped within a new task and will
     * be scheduled to execute independently.
     *
     * @param body - body of the async task
     */
    public static void async(Runnable body)
    {
        runtime.setupAsync(body);
    }

    /**
     * Define a finish scope encapsulating the body
     *
     * This call should only be called within the launchApp {...} scope, since it
     * requires the Loom Runtime to be initialised.
     *
     * All instructions execute sequentially within the body, except for 
     * async {...} calls, which will spawn independent tasks to execute alongside
     * the original thread. 
     *
     * However, once the finish { ... } body is done, it will wait on any 
     * outstanding async calls which still need to complete.
     *
     * @param body - encapsulated body within the finish
     */
    public static void finish(Runnable body)
    {
       runtime.setupFinish(body);
    }
    \end{lstlisting}

    Once again, there is no mention of Continuations or even tasks. This has all been encapsulated within the
    runtime itself. The included javadocs explain the behaviour of the \textbf{async} and \textbf{finish}
    constructs. However, the actual details of what is going on is within the runtime itself. That is where
    the finish scope handling and task spawning takes place. The details of this are explored within the next
    subsection.

    \subsubsection{Runtime Implementation}

    The runtime itself is conceptually separated into two components: thread management and task management.
    The thread management portion handles the thread creation and task scheduling aspects of the runtime. The
    task management portion handles the creation and monitoring of tasks within the runtime. These portions
    are only conceptually separate -- in the code itself both portions go hand-in-hand to make everything
    work.

    Since the thread management aspect of this project is not particularly important, the design was kept
    relatively simple. When the runtime is initialised, a fixed number of worker threads are started up. The
    number of worker threads will not change throughout the course of the job execution.

    There is a single task queue which is shared amongst all the worker threads. This is a simpler model to
    work with that a queue-per-worker with work stealing approach. The worker threads wait until there are
    tasks ready and will pull them off the queue. The worker executes its task and performs any necessary
    cleanup depending on the current state. Finally, the worker once again checks the task queue for any
    additional work to perform, blocking otherwise.

    The actually interesting and relevant detail is how the continuations are managed and the design of the
    async and finish constructs. When the root task is submitted to the runtime framework, a small amount of
    initialisation work is done:

    \begin{lstlisting}
    /**
     * Submit the root task to the work queue
     * @param body - body of the root task to add
     */
    public void submitRoot(Runnable body)
    {
        Continuation cont = new Continuation(scope, () -> Constructs.finish(body));

        root = new Task(cont);
        tasks.offer(root);
    }
    \end{lstlisting}

    The body of the root task is wrapped within a Continuation. The Loom API defines continuation scopes and
    nested continuations, but those features are not used here. Every continuation that is created by the
    runtime belongs to and yields to the same scope. An important point to highlight is that the body is also
    wrapped within a finish scope before it is encapsulated within the continuation. This ensures that any
    async tasks are properly waited on, even if there is no explicit global finish scope defined by the
    library user. Hence, the root task always becomes the last task to complete, which means its completion
    can be used to signal that it is safe to shutdown the runtime.

    The Task class acts as a thin wrapper over the underlying continuation. It handles information about the
    status of the task, child tasks within its finish scope, and the finish scope task. One point of future
    improvement is to potentially move some of the task dependency management into its own class -- similar
    to the EDC design description.

    The following code snippet details the runtime support needed for the async construct:

    \begin{lstlisting}
    /**
     * Setup the provided task as an async construct
     *
     * The async subtask will be associated with the currently executing
     * parent task and will be added to the work queue.
     *
     * The parent task will then be returned to immediately, since the
     * parent does not directly wait on the spawned async until it reaches the
     * end of a finish scope (implicitly or explicitly)
     *
     * @param body - async subtask to setup
     */
    public void setupAsync(Runnable body)
    {
        Task child = new Task(new Continuation(scope, body));

        long tid = Thread.currentThread().getId();
        Task parent = current.get(tid);

        parent.addChild(child);
        tasks.offer(child);
    }
    \end{lstlisting}

    The body of the async is wrapped within its own (non-nested) continuation, which is then wrapped into
    a new task. There is a bit of bookkeeping work performed: the async task belongs to some finish scope,
    so the task that the scope was entered in needs to be informed of a new task. The addChild method
    increments an atomic counter for the finish scope task. When one of these child tasks complete, this
    counter is then decremented. Only when the counter goes to 0 is the finish scope task allowed to
    complete.

    The implementation of the finish construct has a bit more going on:

    \begin{lstlisting}
    /**
     * Setup the finish scope for this task
     *
     * The current task will enter a new finish scope, which is
     * done by pushing itself onto the finish stack.
     *
     * Any new async tasks that will be spawned will point to this task as
     * the finish scope that they reside in.
     *
     * @param body - body to encapsulate
     */
    public void setupFinish(Runnable body)
    {
        long tid = Thread.currentThread().getId();
        Task curr = current.get(tid);

        curr.finish.push(curr);
        body.run();
        curr.finish.pop();

        // Yield until all the child async tasks have finished
        // Then, this continuation will be re-entered
        Continuation.yield(scope);
    }
    \end{lstlisting}

    Before the body of the finish is run, the current finish scope is pushed onto the finish stack. That
    means any async tasks generated within the body of the finish will be associated with this scope. The
    only way that changes is if any one of those async tasks reside within another finish scope within this
    finish scope. In addition, once the body finishes, the finish scope is popped off -- any new async tasks
    will then be associated with the previous finish scope instead of this one. 

    The call to Continuation.yield, as described earlier, will yield the continuation, causing the original
    call to run to return. The runtime does some additional bookkeeping work to determine how to handle the
    suspending task. If there are no child tasks remaining -- or none to begin with, then the suspended task
    can simply be marked as done. Otherwise, the task is treated as suspended and will only be resumed once
    the task count atomic goes to 0.

    Finally, a simple countdown latch is used to signal to the launchApp function that all the tasks have
    completed. As seen earlier in the implementation of launchApp, it makes a call to the runtime to wait
    on the root task. This has been implemented simply by:

    \begin{lstlisting}
    /**
     * Wait until the root task completes
     * @throws InterruptedException - if the latch await is interrupted
     */
    public void waitOnRoot() throws InterruptedException
    {
        latch.await();
    }
    \end{lstlisting}

    The latch starts off with value 1 and this is decremented once the root task has completed, which will
    wake up the await call. Once waitOnRoot returns, the launchApp method will then instruct the runtime to
    shutdown. The runtime shutdown will instruct the worker threads to stop waiting for new tasks and simply
    quit, allowing them to be joined upon. That completes the entire runtime lifecycle.

    \section{Future Work}

    The current implementation shows that it is very possible to implement these high-level constructs with
    the primitives provided by the Loom API. While there are still some unknowns with the fact that Loom is
    still under active development and what will remain from build-to-build is not certain. However, it seems
    reasonable that building off of Continuations is safe enough. There are still some things to be desired,
    like better state information about a continuation, but these may be added in the future.

    The main starting point in porting the Habanero Java library to using Loom instead of Kilim would be at
    the HjSuspendable class and the Kilim Fiber class. Since Kilim requires a weaving step to inject the
    required low-level steps to implement suspending and resuming, methods needs to be explicitly
    ``annotated'' using a throws SuspendableException signature. This is not the case with Loom, since
    continuations are supported within the JVM itself. Therefore, the only requirement is that the
    suspendable portion be wrapped within a continuation.

    The Kilim fiber class does not have a direct equivalent in Loom, at least not in the current build that
    this proof-of-concept was built against. While there is documentation to say that Loom has a Fiber class,
    no such class exists. Therefore, all of the scheduling work still needs to be done with Loom to manage
    the lifecycle of a particular continuation.

    Exception handling is another interesting point to consider. I have not looked at how exceptions are
    handled within Loom continuations. Therefore, one place of investigation is seeing how to capture
    exceptions within async tasks and process them within the finish scope, since this is behaviour described
    within the javadoc for the finish construct within Habanero Java Library implementation. 

    Overall, this proof of concept was productive in getting a feel for the capabilities, strengths, and
    weaknesses of the Loom API and getting an initial gauge of the difficulty in porting the Habanero Java
    Library to it. Many parts of this PoC were designed to mimic the implementation in HJ, so a good portion
    of the continuation handling code should be transferable to the actual library implementation once the
    transition effort to using Loom starts.

\end{document}
